import React, { useState,useRef } from 'react';
import { View, Text, StyleSheet, FlatList, TouchableOpacity, Alert, Image } from 'react-native';
import { Audio } from 'expo-av';
import useRecordingsStore from '../store/recordingsStore';

export default function ImageJudgementPage({ navigation }) {
  const speechTasks = [
    "ë™ë¬¼ ì´ë¦„ ë§í•˜ê¸°: í˜¸ë‘ì´, ì½”ë¼ë¦¬, ê¸°ë¦°",
    "ê·¸ë¦¼ ì„¤ëª…í•˜ê¸° (cookie-theft)"
  ];

  const timerRef = useRef(null);
  const [recordingIndex, setRecordingIndex] = useState(null);
  const [recording, setRecording] = useState(null);
  const [recordings, setRecordings] = useState(Array(speechTasks.length).fill(null));
  const addRecording = useRecordingsStore((state) => state.addRecording);

  const recordingRef = useRef(null);
    const startRecording = async (index) => {
  try {
    if (recordingRef.current) return;

    const { granted } = await Audio.requestPermissionsAsync();
    if (!granted) return;

    await Audio.setAudioModeAsync({
      allowsRecordingIOS: true,
      playsInSilentModeIOS: true,
    });

    const newRecording = new Audio.Recording();
    await newRecording.prepareToRecordAsync(Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY);
    await newRecording.startAsync();

    recordingRef.current = newRecording;
    setRecording(newRecording);  // âœ… ì¶”ê°€
    setRecordingIndex(index);

    if (timerRef.current) clearTimeout(timerRef.current);
    timerRef.current = setTimeout(() => {
      stopRecording();
      setTimeout(() => {
        Alert.alert("â±ï¸ ë…¹ìŒ ì™„ë£Œ", "1ë¶„ì´ ì§€ë‚˜ ìë™ìœ¼ë¡œ ë…¹ìŒì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
      }, 100);
    }, 60000);

  } catch (err) {
    console.error("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:", err);
    Alert.alert("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜");
  }
};

const stopRecording = async () => {
  try {
    if (!recordingRef.current) return;

    if (timerRef.current) {
      clearTimeout(timerRef.current);
      timerRef.current = null;
    }

    await recordingRef.current.stopAndUnloadAsync();
    const uri = recordingRef.current.getURI();

    const newRecordings = [...recordings];
    newRecordings[recordingIndex] = uri;
    setRecordings(newRecordings);

    addRecording('Image', uri);
    recordingRef.current = null;
    setRecording(null); // âœ… ì¶”ê°€
    setRecordingIndex(null);
     console.log('âœ… image ì €ì¥ë¨:', uri);
  } catch (err) {
    console.error("ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:", err);
    Alert.alert("ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜");
  }
};
  return (
    <View style={styles.container}>
      <Text style={styles.title}>ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒë‹¨í•˜ê¸°</Text>

      <Image style={styles.image}
        source={require('../assets/person.jpg')}  
        resizeMode="contain"
      />

      <FlatList
        data={speechTasks}
        keyExtractor={(item, index) => index.toString()}
        renderItem={({ item, index }) => (
          <View style={styles.taskContainer}>
            <Text style={styles.taskText}>â€¢ {item}</Text>
            <TouchableOpacity
              style={styles.recordButton}
              onPress={() => {
                if (recording && recordingIndex === index) {
                  stopRecording();
                } else if (!recording) {
                  startRecording(index);
                } else {
                  Alert.alert("ì•Œë¦¼", "ë‹¤ë¥¸ ë¬¸ì œ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤.");
                }
              }}
            >
              <Text style={styles.buttonText}>
                {recording && recordingIndex === index ? 'â¹ï¸ ì¤‘ì§€' : 'ğŸ™ï¸ ë…¹ìŒ'}
              </Text>
            </TouchableOpacity>

            {recordings[index] && (
              <Text style={styles.uriText}>ë…¹ìŒ ì™„ë£Œ âœ”ï¸</Text>
            )}
          </View>
        )}
      />

      <TouchableOpacity
        style={[styles.nextButton, { backgroundColor: '#5DADE2' }]}
        onPress={() => navigation.navigate('Fluency')}    // âœ… ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
      >
        <Text style={styles.buttonText}>ë‹¤ìŒìœ¼ë¡œ</Text>
      </TouchableOpacity>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: '#FAFAF0', padding: 24 ,marginTop:50},
  title: { fontSize: 28, fontWeight: 'bold', marginBottom: 20, textAlign: 'center', color: '#111' },
  image: { width: '50%', height: 200, borderRadius: 10, marginBottom: 20,marginTop:30,alignSelf:'center' },
  taskContainer: { marginBottom: 20, backgroundColor: '#fff', borderRadius: 10, padding: 15, elevation: 2 },
  taskText: { fontSize: 18, marginBottom: 10, color: '#333' },
  recordButton: { backgroundColor: '#4A90E2', paddingVertical: 10, borderRadius: 8, alignItems: 'center' },
  buttonText: { fontSize: 16, color: '#fff', fontWeight: 'bold' },
  uriText: { fontSize: 14, color: 'green', marginTop: 8, textAlign: 'center' },
  nextButton: { paddingVertical: 14, borderRadius: 12, alignItems: 'center', marginTop: 20 }
});

import React, { useState } from 'react';
import { View, Text, StyleSheet, FlatList, TouchableOpacity, Alert } from 'react-native';
import { Audio } from 'expo-av';
import useRecordingsStore from '../store/recordingsStore';

export default function StorytellingPage({ navigation }) {
  const speechTasks = [
    "ê¸°ë»¤ë˜ ì¼ì„ ì´ì•¼ê¸°í•˜ì„¸ìš”",
    "ìŠ¬íë˜ ì¼ì„ ì´ì•¼ê¸°í•˜ì„¸ìš”",
    "ì–´ì œ ìˆì—ˆë˜ ì¼ì„ ì´ì•¼ê¸°í•˜ì„¸ìš”"
  ];

  
  const [recordingIndex, setRecordingIndex] = useState(null);
  const [recording, setRecording] = useState(null);
  const [recordings, setRecordings] = useState(Array(speechTasks.length).fill(null));

  const addRecording=useRecordingsStore((state)=>state.addRecording);
  const startRecording = async (index) => {
    try {
      await Audio.requestPermissionsAsync();
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      const { recording } = await Audio.Recording.createAsync(
        Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY
      );
      setRecording(recording);
      setRecordingIndex(index);
    } catch (err) {
      console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', err);
      Alert.alert("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜");
    }
  };

  const stopRecording = async () => {
    try {
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      const newRecordings = [...recordings];
      newRecordings[recordingIndex] = uri;
      setRecordings(newRecordings);

      console.log(`ë¬¸ì œ ${recordingIndex + 1} ë…¹ìŒ íŒŒì¼:`, uri);

      addRecording('Story',uri);
      setRecording(null);
      setRecordingIndex(null);
    } catch (err) {
      console.error('ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:', err);
      Alert.alert("ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜");
    }
  };

  return (
    <View style={styles.container}>
      <Text style={styles.title}>ğŸ“– ì´ì•¼ê¸°í•˜ê¸°</Text>

      <FlatList
        data={speechTasks}
        keyExtractor={(item, index) => index.toString()}
        renderItem={({ item, index }) => (
          <View style={styles.taskContainer}>
            <Text style={styles.taskText}>â€¢ {item}</Text>
            <TouchableOpacity
              style={styles.recordButton}
              onPress={() => {
                if (recording && recordingIndex === index) {
                  stopRecording();
                } else if (!recording) {
                  startRecording(index);
                } else {
                  Alert.alert("ì•Œë¦¼", "ë‹¤ë¥¸ ë¬¸ì œ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤.");
                }
              }}
            >
              <Text style={styles.buttonText}>
                {recording && recordingIndex === index ? 'â¹ï¸ ì¤‘ì§€' : 'ğŸ™ï¸ ë…¹ìŒ'}
              </Text>
            </TouchableOpacity>

            {recordings[index] && (
              <Text style={styles.uriText}>ë…¹ìŒ ì™„ë£Œ âœ”ï¸</Text>
            )}
          </View>
        )}
      />

      <TouchableOpacity
        style={[styles.nextButton, { backgroundColor: '#5DADE2' }]}
        onPress={() => navigation.navigate('Result')}    // âœ… ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™
      >
        <Text style={styles.buttonText}>ê²°ê³¼ ë³´ê¸°</Text>
      </TouchableOpacity>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: '#FAFAF0', padding: 24, marginTop: 40 },
  title: { fontSize: 28, fontWeight: 'bold', marginBottom: 20, textAlign: 'center', color: '#111' },
  taskContainer: { marginBottom: 30, backgroundColor: '#fff', borderRadius: 10, padding: 15, elevation: 2 },
  taskText: { fontSize: 18, marginBottom: 10, color: '#333' },
  recordButton: { backgroundColor: '#4A90E2', paddingVertical: 10, borderRadius: 8, alignItems: 'center' },
  buttonText: { fontSize: 16, color: '#fff', fontWeight: 'bold' },
  uriText: { fontSize: 14, color: 'green', marginTop: 8, textAlign: 'center' },
  nextButton: { paddingVertical: 14, borderRadius: 12, alignItems: 'center', marginTop: 20 }
});
